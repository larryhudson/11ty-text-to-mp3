# 11ty-text-to-mp3

This project is an example of how you can use Microsoft's Cognitive Services Speech API to generate MP3 audio versions of your Eleventy pages.

## How to get started

1. Clone this repo
2. Sign up for an [Azure account](https://portal.azure.com/)
3. Once you're logged into the Azure portal, add a new resource connected to the 'Cognitive Services - Speech service'. You can choose the free tier. Take note of the 'location' or 'region' that you choose when you create the resource.
4. Once you've created the new resource, click 'Manage keys' and get your API key
5. Go to the [list of Azure regions](https://gist.github.com/ausfestivus/04e55c7d80229069bf3bc75870630ec8) and find the short name (in the last column) of the region you chose above
6. Create a `.env` file with the following variables:

```
MICROSOFT_TTS_SPEECH_KEY=<API KEY FOR YOUR AZURE SPEECH SERVICE>
MICROSOFT_TTS_REGION=<SHORT NAME FOR THE RESOURCE REGION>
```

7. Try running `npm run build` to test the API works with your new resource.

## How it works

### Adding a custom collection for pages to generate MP3s from

In `.eleventy.js`, we add a custom collection called `generateMp3`, which adds any items that have an `mp3Url` set in the frontmatter.

This means we can keep track of which pages we want to turn into audio versions.

### Paginating over the custom collection

In `src/mp3-version.11ty.js`, we paginate over the `generateMp3` collection with `size: 1`. This means that for each page in the `generateMp3` collection, we'll create a new page.

`.11ty.js` files make it possible to return buffer data rather than just text. We're taking advantage of that by returning the audio buffer generated by Microsoft's API. We're also setting the permalink to the original `mp3Url` set in the original page frontmatter.

### Generating the audio data with Microsoft's Cognitive Services Speech API

In `utils/text-to-speech.js`, we take some HTML, turn it into plain text with the `html-to-text` NPM library, and then send it to Microsoft's Cognitive Services Speech API to generate an audio version.

Before we generate the audio, we generate an MD5 hash based on the text content. We save the generated audio buffer data in a cache using the `@11ty/eleventy-fetch` package. We use that MD5 hash to identify the cached data - that way, if we re-run the build command and the text content has not changed, it will used the cached data. This is important because Microsoft's free tier only allows 5 hours of audio per month.

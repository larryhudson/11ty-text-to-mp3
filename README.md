# 11ty-text-to-mp3

This project is an example of how you can use Microsoft's Cognitive Services Speech API to generate MP3 audio versions of your Eleventy pages.

You can find the hosted demo site here: [https://11ty-text-to-mp3.netlify.app/](https://11ty-text-to-mp3.netlify.app/)

## How to get started

1. Clone this repo
2. Sign up for an [Azure account](https://portal.azure.com/)
3. Once you're logged into the Azure portal, add a new resource connected to the 'Cognitive Services - Speech service'. You can choose the free tier. Take note of the 'location' or 'region' that you choose when you create the resource.
4. Once you've created the new resource, click 'Manage keys' and get your API key
5. Go to the [list of Azure regions](https://gist.github.com/ausfestivus/04e55c7d80229069bf3bc75870630ec8) and find the short name (in the last column) of the region you chose above
6. Create a `.env` file with the following variables:

```
MICROSOFT_TTS_SPEECH_KEY=<API KEY FOR YOUR AZURE SPEECH SERVICE>
MICROSOFT_TTS_REGION=<SHORT NAME FOR THE RESOURCE REGION>
```

7. Try running `npm run build` to test the API works with your new resource.

## How it works

### Adding a custom collection for pages to generate MP3s from

In `.eleventy.js`, we add a custom collection called `generateMp3`, which adds any items that have an `mp3Url` set in the frontmatter.

This means we can keep track of which pages we want to turn into audio versions.

### Paginating over the custom collection

In `src/mp3-version.11ty.js`, we paginate over the `generateMp3` collection with `size: 1`. This means that for each page in the `generateMp3` collection, we'll create a new page.

`.11ty.js` files make it possible to return buffer data rather than just text. We're taking advantage of that by returning the audio buffer generated by Microsoft's API. We're also setting the permalink to the original `mp3Url` set in the original page frontmatter.

### Generating the audio data with Microsoft's Cognitive Services Speech API

In `utils/text-to-speech.js`, we take some HTML, turn it into plain text with the `html-to-text` NPM library, and then send it to Microsoft's Cognitive Services Speech API to generate an audio version.

Before we generate the audio, we generate an MD5 hash based on the text content. We save the generated audio buffer data in a cache using the `@11ty/eleventy-fetch` package. We use that MD5 hash to identify the cached data - that way, if we re-run the build command and the text content has not changed, it will used the cached data. This is important because Microsoft's free tier only allows 5 hours of audio per month.

### Caching between Netlify builds

If you generate new audio versions every time your site rebuilds, you'll use up your free tier API quota very quickly. This project uses the `netlify-plugin-cache` to persist the `.cache` folder (used by `@11ty/eleventy-fetch`) between builds on Netlify. The Netlify build plugin is configured in `netlify.toml`.

## Generating a podcast feed

This project also generates a podcast RSS feed with the audio versions of the pages. This means readers can add the feed to their podcast player and listen to the posts in their preferred app.

To create a podcast feed, we need to:

1. make a list of podcast episodes during the Eleventy build (when we have access to the `generateMp3` collection), then,
2. get some information from the MP3 files after the build has completed, and create a podcast feed

This is how it works:

### 1. Making the list of podcast episodes during build

In `src/podcast-info.11ty.js`, we create a JSON file (`/podcast-info.json`) with most of the data that the podcast feed needs - an array of podcast episodes with titles, descriptions, dates and links. That JSON file gets written to the site's output directory.

### 2. Creating the podcast feed after the build completes

in `.eleventy.js`, we add an event that runs after the build has completed, using `eleventyConfig.on('eleventy.after')`.

We look at the generated MP3 files in the output folder, and get the file size in bytes and the duration of the audio files. We need to include this information in the podcast feed so that podcast apps can show this information to listeners before the listeners download the episodes.

Then, we use the `podcast` NPM package to create a podcast feed using the data above. We write the final `podcast.xml` file to the output directory and delete the temporary `podcast-info.json` file.
